\section{Technologies used}

This section will go through the main technologies employed in this project that were crucial in achieving the final result.

\subsection{The Software}

\textit{Python} is a high-level interpreted general-purpose programming language that supports vast and extensive external libraries that are constantly evolving. \textit{PyCharm Code Editor} was used to combine Python code development while also improving usability and user experience. Additionally, the \textit{Anaconda} software application was employed to facilitate package management and distribution.

\subsection{The Libraries}

\textit{PyTorch} is one of the most popular free open source and powerful \gls{DL} frameworks, and was used in this research to build the entire classification pipeline.

\textit{Numpy} is a key Python library for scientific computing that supports massive, multidimensional arrays, complex matrix arithmetic, and much more. This package was highly helpful for data pre-processing as well as matrix arithmetic calculation in the classication model.

\textit{Pandas} was one of the most used libraries during this study as it is a fast, powerful, and user-friendly data manipulation and analysis tool. It was used to represent the datasets as \textit{Python} objects and to perform any related data processing or manipulation needed.

\textit{Scikit-learn} is another key library for implementing statistics and machine learning models. \textit{Scikit-learn} provides the implementation of several ML models for regression, classification, and clustering; however, in this research, it was mostly used for classification models, data splitting, data preprocessing, and performance metric calculation.

Last but not least, \textit{Matplotlib} is a \textit{Python} package that was used to plot 2D graphs and other high-quality figures with statistical data which provided a better understanding of a dataset.